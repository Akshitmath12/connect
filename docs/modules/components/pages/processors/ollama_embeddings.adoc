= ollama_embeddings
:type: processor
:status: experimental
:categories: ["AI"]



////
     THIS FILE IS AUTOGENERATED!

     To make changes, edit the corresponding source file under:

     https://github.com/redpanda-data/connect/tree/main/internal/impl/<provider>.

     And:

     https://github.com/redpanda-data/connect/tree/main/cmd/tools/docs_gen/templates/plugin.adoc.tmpl
////


component_type_dropdown::[]


Processor that uses the Ollama API to create vector embeddings.

Introduced in version 4.32.0.


[tabs]
======
Common::
+
--

```yml
# Common config fields, showing default values
label: ""
ollama_embeddings:
  server_address: http://127.0.0.1:11434 # No default (optional)
  model: nomic-embed-text # No default (required)
  text: "" # No default (optional)
```

--
Advanced::
+
--

```yml
# All config fields, showing default values
label: ""
ollama_embeddings:
  server_address: http://127.0.0.1:11434 # No default (optional)
  ollama_directory: "" # No default (optional)
  model: nomic-embed-text # No default (required)
  text: "" # No default (optional)
```

--
======

Sends text to your chosen Ollama large language model (LLM) and creates vector embeddings, using the Ollama API. Vector embeddings are long arrays of numbers that represent values or objects, in this case text. 


See https://ollama.com/[https://ollama.com/^] for more information.

== Fields

=== `server_address`

The address of the Ollama server to use. By default, a local Ollama server starts and runs unless you specify the address of a remote server.


*Type*: `string`


```yml
# Examples

server_address: http://127.0.0.1:11434
```

=== `ollama_directory`

Unpack the Ollama binary to this directory. Default is `/tmp`.


*Type*: `string`


=== `model`

The name of the Ollama LLM to use. For a full list of models, see the https://ollama.com/models[Ollama website].


*Type*: `string`


```yml
# Examples

model: nomic-embed-text

model: mxbai-embed-large

model: snowflake-artic-embed

model: all-minilm
```

=== `text`

The text you want to create vector embeddings for. By default, the processor submits the entire payload as a string.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].


*Type*: `string`



