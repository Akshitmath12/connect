= gcp_vertex_ai_chat
:type: processor
:status: experimental
:categories: ["AI"]



////
     THIS FILE IS AUTOGENERATED!

     To make changes, edit the corresponding source file under:

     https://github.com/redpanda-data/connect/tree/main/internal/impl/<provider>.

     And:

     https://github.com/redpanda-data/connect/tree/main/cmd/tools/docs_gen/templates/plugin.adoc.tmpl
////

// Â© 2024 Redpanda Data Inc.


component_type_dropdown::[]


Generates responses to messages in a chat conversation, using the Vertex AI API.

Introduced in version 4.33.0.


[tabs]
======
Common::
+
--

```yml
# Common config fields, showing default values
label: ""
gcp_vertex_ai_chat:
  project: "" # No default (required)
  credentials_json: "" # No default (optional)
  location: us-central1 # No default (optional)
  model: gemini-1.5-pro-001 # No default (required)
  prompt: "" # No default (optional)
```

--
Advanced::
+
--

```yml
# All config fields, showing default values
label: ""
gcp_vertex_ai_chat:
  project: "" # No default (required)
  credentials_json: "" # No default (optional)
  location: us-central1 # No default (optional)
  model: gemini-1.5-pro-001 # No default (required)
  prompt: "" # No default (optional)
  system_prompt: "" # No default (optional)
```

--
======

This processor sends prompts to your chosen large language model (LLM) and generates text from the responses, using the Vertex AI API.

For more information, see the https://cloud.google.com/vertex-ai/docs[Vertex AI documentation^].

== Fields

=== `project`

GCP project ID to use


*Type*: `string`


=== `credentials_json`

An optional field to set google Service Account Credentials json.
[CAUTION]
====
This field contains sensitive information that usually shouldn't be added to a config directly, read our xref:configuration:secrets.adoc[secrets page for more info].
====



*Type*: `string`


=== `location`

The location of the model if using a fined tune model. For base models this can be omitted


*Type*: `string`


```yml
# Examples

location: us-central1
```

=== `model`

The name of the LLM to use. For a full list of models, see the https://console.cloud.google.com/vertex-ai/model-garden[Vertex AI Model Garden].


*Type*: `string`


```yml
# Examples

model: gemini-1.5-pro-001

model: gemini-1.5-flash-001
```

=== `prompt`

The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].


*Type*: `string`


=== `system_prompt`

The system prompt to submit to the Vertex AI LLM.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].


*Type*: `string`



